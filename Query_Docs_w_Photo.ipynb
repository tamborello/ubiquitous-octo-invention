{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Query the Document Corpus with a Photo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Process the Photo for Feature and Entity Tags</h2>\n",
    "[Quickstart: Use the Image Analysis client library or REST API](https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/quickstarts-sdk/image-analysis-client-library?tabs=visual-studio&pivots=programming-language-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import io, os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = \"\"\n",
    "endpoint = \"\"\n",
    "\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "image_doc = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a local image for processing\n",
    "local_img = open('Convertible_on_a_Grassy_Hill/aut-21-rk0210-07p.jpg', 'rb')\n",
    "\n",
    "# with open('Convertible_on_a_Grassy_Hill/aut-21-rk0210-07p.jpg', 'rb') as f:\n",
    "#     local_img = f.read()\n",
    "\n",
    "# local_img = io.BytesIO(local_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undocumented behavior! \n",
    "# These in_stream methods apparently change the value of the local_img variable! \n",
    "# So load the image anew before calling each in_stream method.\n",
    "local_img = open('Convertible_on_a_Grassy_Hill/aut-21-rk0210-07p.jpg', 'rb')\n",
    "\n",
    "description_result = computervision_client.describe_image_in_stream(local_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_img = open('Convertible_on_a_Grassy_Hill/aut-21-rk0210-07p.jpg', 'rb')\n",
    "\n",
    "analysis_result = computervision_client.analyze_image_in_stream(local_img, [\"categories\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_img = open('Convertible_on_a_Grassy_Hill/aut-21-rk0210-07p.jpg', 'rb')\n",
    "\n",
    "tag_result = computervision_client.tag_image_in_stream(local_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Caption: {'additional_properties': {}, 'tags': ['grass', 'outdoor', 'sky', 'red', 'field', 'transport', 'grassy', 'parked', 'car', 'lush'], 'captions': [<azure.cognitiveservices.vision.computervision.models._models_py3.ImageCaption object at 0x000001C670F68160>], 'request_id': '51aceec5-8b43-4349-9f88-b162c99a109a', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x000001C66F6DE550>, 'model_version': '2021-05-01'}\n",
      "\n",
      "Categories: {'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x000001C670AAF8E0>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x000001C670AAF9A0>], 'adult': None, 'color': None, 'image_type': None, 'tags': None, 'description': None, 'faces': None, 'objects': None, 'brands': None, 'request_id': '711c4db1-1ac9-417d-ae8c-3e3156530749', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x000001C670F452B0>, 'model_version': '2021-05-01'}\n",
      "\n",
      "Tags: {'additional_properties': {}, 'tags': [<azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C0D0>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C160>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C6A0>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C4C0>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C700>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C400>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C790>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C7F0>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C850>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C8B0>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C910>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A2C9A0>], 'request_id': 'ebb761e6-0e3f-4dfe-b65d-15fa4ba752b3', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x000001C670A2C640>, 'model_version': '2021-04-01'} \n"
     ]
    }
   ],
   "source": [
    "print(f\"Descriptive Caption: {description_result}\\n\\nCategories: {analysis_result}\\n\\nTags: {tag_result} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a red car parked on grass near a road and trees, 41%\n",
      "others_: 0\n",
      "outdoor_: 4\n",
      "grass: 100\n",
      "vehicle: 100\n",
      "outdoor: 99\n",
      "land vehicle: 98\n",
      "sky: 98\n",
      "wheel: 97\n",
      "transport: 93\n",
      "car: 90\n",
      "red: 87\n",
      "convertible: 81\n",
      "field: 71\n",
      "sunset: 48\n",
      "Image Doc: a red car parked on grass near a road and trees others outdoor grass vehicle outdoor land vehicle sky wheel transport car red convertible field sunset\n"
     ]
    }
   ],
   "source": [
    "for caption in description_result.captions:\n",
    "    print(f\"{caption.text}, {caption.confidence * 100:.0f}%\")\n",
    "    image_doc = caption.text\n",
    "for category in analysis_result.categories:\n",
    "    print(f\"{category.name}: {category.score * 100:.0f}\")\n",
    "    image_doc = image_doc + \" \" + category.name[:-1]\n",
    "for tag in tag_result.tags:\n",
    "    print(f\"{tag.name}: {tag.confidence * 100:.0f}\")\n",
    "    image_doc = image_doc + \" \" + tag.name\n",
    "print(f\"Image Doc: {image_doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'categories': [<azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x000001C671C3B340>, <azure.cognitiveservices.vision.computervision.models._models_py3.Category object at 0x000001C670A37460>], 'adult': None, 'color': <azure.cognitiveservices.vision.computervision.models._models_py3.ColorInfo object at 0x000001C671C3B9D0>, 'image_type': None, 'tags': [<azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A37640>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A37D30>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A37580>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A37AC0>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A37A00>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A379D0>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A371C0>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A37FD0>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A37400>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A37070>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A373D0>, <azure.cognitiveservices.vision.computervision.models._models_py3.ImageTag object at 0x000001C670A37B80>], 'description': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageDescriptionDetails object at 0x000001C671C3BFA0>, 'faces': None, 'objects': None, 'brands': None, 'request_id': 'ec1f7ee4-6799-4d99-af50-6161bf573331', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x000001C670A37760>, 'model_version': '2021-05-01'}\n"
     ]
    }
   ],
   "source": [
    "local_img = open('Convertible_on_a_Grassy_Hill/aut-21-rk0210-07p.jpg', 'rb')\n",
    "\n",
    "analysis_result = computervision_client.analyze_image_in_stream(local_img, visual_features=[\"description\", \"categories\", \"color\", \"tags\"])\n",
    "\n",
    "print(analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_attribute_map',\n",
       " '_classify',\n",
       " '_create_xml_node',\n",
       " '_flatten_subtype',\n",
       " '_get_rest_key_parts',\n",
       " '_infer_class_models',\n",
       " '_subtype_map',\n",
       " '_validation',\n",
       " 'additional_properties',\n",
       " 'adult',\n",
       " 'as_dict',\n",
       " 'brands',\n",
       " 'categories',\n",
       " 'color',\n",
       " 'description',\n",
       " 'deserialize',\n",
       " 'enable_additional_properties_sending',\n",
       " 'faces',\n",
       " 'from_dict',\n",
       " 'image_type',\n",
       " 'is_xml_model',\n",
       " 'metadata',\n",
       " 'model_version',\n",
       " 'objects',\n",
       " 'request_id',\n",
       " 'serialize',\n",
       " 'tags',\n",
       " 'validate']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_attribute_map',\n",
       " '_classify',\n",
       " '_create_xml_node',\n",
       " '_flatten_subtype',\n",
       " '_get_rest_key_parts',\n",
       " '_infer_class_models',\n",
       " '_subtype_map',\n",
       " '_validation',\n",
       " 'additional_properties',\n",
       " 'as_dict',\n",
       " 'captions',\n",
       " 'deserialize',\n",
       " 'enable_additional_properties_sending',\n",
       " 'from_dict',\n",
       " 'is_xml_model',\n",
       " 'serialize',\n",
       " 'tags',\n",
       " 'validate']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(analysis_result.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a red car parked on grass near a road and trees'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_result.description.captions[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a red car parked on grass near a road and trees, 41%\n",
      "others_: 0\n",
      "outdoor_: 4\n",
      "grass: 100\n",
      "vehicle: 100\n",
      "outdoor: 99\n",
      "land vehicle: 98\n",
      "sky: 98\n",
      "wheel: 97\n",
      "transport: 93\n",
      "car: 90\n",
      "red: 87\n",
      "convertible: 81\n",
      "field: 71\n",
      "sunset: 48\n",
      "Image Doc: a red car parked on grass near a road and trees others outdoor grass vehicle outdoor land vehicle sky wheel transport car red convertible field sunset\n"
     ]
    }
   ],
   "source": [
    "image_doc = \"\"\n",
    "for caption in analysis_result.description.captions:\n",
    "    print(f\"{caption.text}, {caption.confidence * 100:.0f}%\")\n",
    "    image_doc = caption.text\n",
    "for category in analysis_result.categories:\n",
    "    print(f\"{category.name}: {category.score * 100:.0f}\")\n",
    "    image_doc = image_doc + \" \" + category.name[:-1]\n",
    "for tag in analysis_result.tags:\n",
    "    print(f\"{tag.name}: {tag.confidence * 100:.0f}\")\n",
    "    image_doc = image_doc + \" \" + tag.name\n",
    "print(f\"Image Doc: {image_doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roman Coliseum\n",
    "# remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n",
    "# critical infrastructure drawing\n",
    "# remote_image_url = \"https://images.squarespace-cdn.com/content/555b2d4ee4b011aa38092227/1469124849953-G8OUJ6F39R9B4DG73C7B/?content-type=image%2Fjpeg\"\n",
    "# people at a construction site\n",
    "# remote_image_url = \"https://th.bing.com/th/id/OIP.1Nr_abqE0UUcNDOD92U6pQHaEO?pid=ImgDet&rs=1\"\n",
    "# people touring a plant\n",
    "# remote_image_url = \"https://th.bing.com/th/id/OIP.1Nr_abqE0UUcNDOD92U6pQHaEO?pid=ImgDet&rs=1\"\n",
    "# remote_image_url = \"https://th.bing.com/th/id/OIP.b2AQ4CdK0phAxQH04HbSpQHaE7?pid=ImgDet&rs=1\"\n",
    "# remote_image_url = \"https://cdn.getyourguide.com/img/tour/4c98e2066d198.png/148.jpg\"\n",
    "# Man and woman on ship deck with muddy core samples\n",
    "# remote_image_url = \"https://scx2.b-cdn.net/gfx/news/hires/2018/4-reconstructi.jpg\"\n",
    "# Red 1957 Thunderbird on a hill\n",
    "remote_image_url = \"https://www.kimballstock.com/pix/car/p/02/aut-21-rk0210-07p.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an image - remote =====\n",
      "Description of remote image: \n",
      "'a man and a woman working on a construction site' with confidence 35.13%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Describe an Image - remote\n",
    "This example describes the contents of an image with the confidence score.\n",
    "'''\n",
    "print(\"===== Describe an image - remote =====\")\n",
    "# Call API\n",
    "description_results = computervision_client.describe_image(remote_image_url)\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "        image_doc = image_doc + caption.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Categorize an image - remote =====\n",
      "Categories from remote image: \n",
      "'people_' with confidence 45.70%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Categorize an Image - remote\n",
    "This example extracts (general) categories from a remote image with a confidence score.\n",
    "'''\n",
    "print(\"===== Categorize an image - remote =====\")\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"categories\"]\n",
    "# Call API with URL and features\n",
    "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))\n",
    "        image_doc = image_doc + \" \" + category.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'clothing' with confidence 99.79%\n",
      "'person' with confidence 99.38%\n",
      "'blue-collar worker' with confidence 98.34%\n",
      "'workwear' with confidence 95.54%\n",
      "'engineer' with confidence 93.49%\n",
      "'construction worker' with confidence 93.46%\n",
      "'hard hat' with confidence 92.09%\n",
      "'man' with confidence 86.37%\n",
      "'technician' with confidence 85.54%\n",
      "'ground' with confidence 72.94%\n",
      "'outdoor' with confidence 69.65%\n",
      "'construction' with confidence 58.89%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Tag an Image - remote\n",
    "This example returns a tag (key word) for each thing in the image.\n",
    "'''\n",
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "        image_doc = image_doc + \" \" + tag.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - remote =====\n",
      "Detecting objects in remote image:\n",
      "object at location 213, 365, 85, 208\n",
      "object at location 218, 402, 179, 384\n",
      "object at location 238, 417, 298, 416\n",
      "object at location 116, 419, 60, 386\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Detect Objects - remote\n",
    "This example detects different kinds of objects with bounding boxes in a remote image.\n",
    "'''\n",
    "print(\"===== Detect Objects - remote =====\")\n",
    "# Get URL image with different objects\n",
    "remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
    "# Call API with URL\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
    "\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Faces - remote =====\n",
      "Faces in the remote image: \n",
      "'Male' of age 39 at location 118, 159, 212, 253\n",
      "'Male' of age 54 at location 492, 111, 582, 201\n",
      "'Female' of age 55 at location 18, 153, 102, 237\n",
      "'Female' of age 33 at location 386, 166, 467, 247\n",
      "'Female' of age 18 at location 235, 158, 311, 234\n",
      "'Female' of age 8 at location 323, 163, 391, 231\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Detect Faces - remote\n",
    "This example detects faces in a remote image, gets their gender and age, \n",
    "and marks them with a bounding box.\n",
    "'''\n",
    "print(\"===== Detect Faces - remote =====\")\n",
    "# Get an image with faces\n",
    "remote_image_url_faces = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/faces.jpg\"\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"faces\"]\n",
    "# Call the API with remote URL and features\n",
    "detect_faces_results_remote = computervision_client.analyze_image(remote_image_url_faces, remote_image_features)\n",
    "\n",
    "# Print the results with gender, age, and bounding box\n",
    "print(\"Faces in the remote image: \")\n",
    "if (len(detect_faces_results_remote.faces) == 0):\n",
    "    print(\"No faces detected.\")\n",
    "else:\n",
    "    for face in detect_faces_results_remote.faces:\n",
    "        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
    "        face.face_rectangle.left, face.face_rectangle.top, \\\n",
    "        face.face_rectangle.left + face.face_rectangle.width, \\\n",
    "        face.face_rectangle.top + face.face_rectangle.height))\n",
    "        # image_doc = image_doc + \" \" + f\"{face.gender} of age {face.age}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a man and a woman working on a construction site people_ clothing person blue-collar worker workwear engineer construction worker hard hat man technician ground outdoor construction'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Query Loving Swirles Corpus</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man woman working construction site people clothing person blue collar worker workwear engineer construction worker hard hat man technician ground outdoor construction\n",
      "Agency: Homeland Security Department, Title: Agency Information Collection Activities: Declaration of Person Who Performed Repairs, Score: 0.3448437750339508\n",
      "Agency: Justice Department, Title: Notice Pursuant to the National Cooperative Research and Production Act of 1993-International 2-Up ATV Manufacturers' Association, Score: 0.328750878572464\n",
      "Agency: Justice Department, Title: Manufacturer of Controlled Substances; Notice of Application, Score: 0.32324427366256714\n",
      "Agency: Federal Reserve System, Title: Formations of, Acquisitions by, and Mergers of Bank Holding Companies, Score: 0.3212725520133972\n",
      "Agency: Justice Department, Title: Manufacturer of Controlled Substances; Notice of Application, Score: 0.32115626335144043\n",
      "Agency: Justice Department, Title: Notice of Lodging of Consent Decree Under the Comprehensive Environmental Response, Compensation and Liability Act (“CERCLA”), Score: 0.31687307357788086\n",
      "Agency: Securities and Exchange Commission, Title: Sunshine Act Meeting, Score: 0.31421756744384766\n",
      "Agency: Justice Department, Title: Sunshine Act Meeting, Score: 0.3141482472419739\n",
      "Agency: Justice Department, Title: Manufacturer of Controlled Substances; Notice of Application, Score: 0.3139357268810272\n",
      "Agency: Securities and Exchange Commission, Title: In the Matter of BIH Corporation; Order of Suspension of Trading, Score: 0.31324857473373413\n"
     ]
    }
   ],
   "source": [
    "from utils.dataclean import dataclean\n",
    "from testRG import test_reverent_galileo\n",
    "import json\n",
    "\n",
    "dc = dataclean(image_doc)\n",
    "print(dc)\n",
    "\n",
    "results = json.loads(test_reverent_galileo(dc))\n",
    "# print(results)\n",
    "for result in results:\n",
    "    print(f\"Agency: {result.get('Agency')}, Title: {result.get('Title')}, Score: {result.get('Similarity Score')}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Action': '60-Day Notice and request for comments; Extension of an existing collection of information: 1651-0048.', 'Agency': 'Homeland Security Department', 'Document Number': 'E9-2078', 'Raw Text URL': 'https://www.federalregister.gov/documents/full_text/text/2009/01/30/E9-2078.txt', 'Similarity Score': 0.3448437750339508, 'Title': 'Agency Information Collection Activities: Declaration of Person Who Performed Repairs', 'Type': 'Notice'}, {'Action': '(no data)', 'Agency': 'Justice Department', 'Document Number': '04-27541', 'Raw Text URL': 'https://www.federalregister.gov/documents/full_text/text/2004/12/16/04-27541.txt', 'Similarity Score': 0.328750878572464, 'Title': \"Notice Pursuant to the National Cooperative Research and Production Act of 1993-International 2-Up ATV Manufacturers' Association\", 'Type': 'Notice'}, {'Action': '(no data)', 'Agency': 'Justice Department', 'Document Number': '04-15771', 'Raw Text URL': 'https://www.federalregister.gov/documents/full_text/text/2004/07/13/04-15771.txt', 'Similarity Score': 0.32324427366256714, 'Title': 'Manufacturer of Controlled Substances; Notice of Application', 'Type': 'Notice'}, {'Action': '(no data)', 'Agency': 'Federal Reserve System', 'Document Number': '04-14291', 'Raw Text URL': 'https://www.federalregister.gov/documents/full_text/text/2004/06/24/04-14291.txt', 'Similarity Score': 0.3212725520133972, 'Title': 'Formations of, Acquisitions by, and Mergers of Bank Holding Companies', 'Type': 'Notice'}, {'Action': '(no data)', 'Agency': 'Justice Department', 'Document Number': 'E8-28853', 'Raw Text URL': 'https://www.federalregister.gov/documents/full_text/text/2008/12/05/E8-28853.txt', 'Similarity Score': 0.32115626335144043, 'Title': 'Manufacturer of Controlled Substances; Notice of Application', 'Type': 'Notice'}, {'Action': '(no data)', 'Agency': 'Justice Department', 'Document Number': '04-12623', 'Raw Text URL': 'https://www.federalregister.gov/documents/full_text/text/2004/06/04/04-12623.txt', 'Similarity Score': 0.31687307357788086, 'Title': 'Notice of Lodging of Consent Decree Under the Comprehensive Environmental Response, Compensation and Liability Act (“CERCLA”)', 'Type': 'Notice'}, {'Action': '(no data)', 'Agency': 'Securities and Exchange Commission', 'Document Number': 'E8-25715', 'Raw Text URL': 'https://www.federalregister.gov/documents/full_text/text/2008/10/29/E8-25715.txt', 'Similarity Score': 0.31421756744384766, 'Title': 'Sunshine Act Meeting', 'Type': 'Notice'}, {'Action': '(no data)', 'Agency': 'Justice Department', 'Document Number': '2011-14929', 'Raw Text URL': 'https://www.federalregister.gov/documents/full_text/text/2011/06/17/2011-14929.txt', 'Similarity Score': 0.3141482472419739, 'Title': 'Sunshine Act Meeting', 'Type': 'Notice'}, {'Action': '(no data)', 'Agency': 'Justice Department', 'Document Number': '04-12462', 'Raw Text URL': 'https://www.federalregister.gov/documents/full_text/text/2004/06/03/04-12462.txt', 'Similarity Score': 0.3139357268810272, 'Title': 'Manufacturer of Controlled Substances; Notice of Application', 'Type': 'Notice'}, {'Action': '(no data)', 'Agency': 'Securities and Exchange Commission', 'Document Number': 'E9-2918', 'Raw Text URL': 'https://www.federalregister.gov/documents/full_text/text/2009/02/10/E9-2918.txt', 'Similarity Score': 0.31324857473373413, 'Title': 'In the Matter of BIH Corporation; Order of Suspension of Trading', 'Type': 'Notice'}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Query JFK Assassination Corpus with the Photo Document</h2>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d986285629ceab87759b8909071c4264024d8b334be9754534dafa9c85ac3856"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
